<!DOCTYPE html>
<html>
   <head>
      <style>
         td, th {
         border: 0px solid black;
         }
         img{
         padding: 5px;
         }
      </style>
      <title>CLIP for All Things Zero-Shot Sketch-Based Image Retrieval, Fine-Grained or Not</title>
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <!--  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
         <script>
           window.dataLayer = window.dataLayer || [];
         
           function gtag() {
             dataLayer.push(arguments);
           }
         
           gtag('js', new Date());
         
           gtag('config', 'G-PYVRSFMDRL');
         
         
         
         </script> -->
      <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
         rel="stylesheet">
      <link rel="stylesheet" href="./static/css/bulma.min.css">
      <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
      <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
      <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
      <link rel="stylesheet"
         href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
      <link rel="stylesheet" href="./static/css/index.css">
      <link rel="icon" href="./static/images/favicon.svg">
      <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
      <link rel="stylesheet" href="css/app.css">
      <link rel="stylesheet" href="css/bootstrap.min.css">
      <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
      <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
      <script defer src="./static/js/fontawesome.all.min.js"></script>
      <script src="./static/js/bulma-carousel.min.js"></script>
      <script src="./static/js/bulma-slider.min.js"></script>
      <script src="./static/js/index.js"></script>
   </head>
   <!-- <body>
      <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
          <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>
        </div>
        <div class="navbar-menu">
          <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="https://keunhong.com">
            <span class="icon">
                <i class="fas fa-home"></i>
            </span>
            </a>
      
            <div class="navbar-item has-dropdown is-hoverable">
              <a class="navbar-link">
                More Research
              </a>
              <div class="navbar-dropdown">
                <a class="navbar-item" href="https://hypernerf.github.io">
                  HyperNeRF
                </a>
                <a class="navbar-item" href="https://nerfies.github.io">
                  Nerfies
                </a>
                <a class="navbar-item" href="https://latentfusion.github.io">
                  LatentFusion
                </a>
                <a class="navbar-item" href="https://photoshape.github.io">
                  PhotoShape
                </a>
              </div>
            </div>
          </div>
      
        </div>
      </nav> -->
   <section class="hero">
      <div class="hero-body">
         <div class="container is-max-desktop">
            <div class="columns is-centered">
               <div class="column has-text-centered">
                  <h1 class="title is-1 publication-title", style="color:purple;">CLIP for All Things Zero-Shot Sketch-Based Image Retrieval</h1>
                  <h1 class="title is-4 publication-title">Fine-Grained or Not</h1>
                  <div class="is-size-5 publication-authors">
                     <span class="author-block">
                     <a href="https://aneeshan95.github.io/">Aneeshan Sain</a><sup>1,2</sup>,</span>
                     <span class="author-block">
                     <a href="https://ayankumarbhunia.github.io/">Ayan Kumar Bhunia</a><sup>1</sup>,</span>
                     <span class="author-block">
                     <a href="http://www.pinakinathc.me/">Pinaki Nath Chowdhury</a><sup>1,2</sup>,</span>
                     <span class="author-block">
                     <a href="https://subhadeepkoley.github.io/">Subhadeep Koley</a><sup>1,2</sup>,</span>
                     <span class="author-block">
                     <br>
                     <a href="http://personal.ee.surrey.ac.uk/Personal/T.Xiang/index.html">Tao Xiang</a><sup>1,2</sup>,</span>
                     <span class="author-block">
                     <a href="http://personal.ee.surrey.ac.uk/Personal/Y.Song/">Yi-Zhe Song</a><sup>1,2</sup></span>	  
                     </span>
                  </div>
                  <div class="is-size-5 publication-authors">
                     <span class="author-block"><sup>1</sup>SketchX, CVSSP, University of Surrey, United Kingdom</span>
                     <span class="author-block"><sup>2</sup>iFlyTek-Surrey Joint Research Centre on Artifiial Intelligence</span>
                  </div>
                  <!--     <div class="column has-text-centered">
                     <a href="as">ICLR 2023</a>
                     </span>
                     </div> -->
                  <div class="column has-text-centered">
                     <div class="publication-links">
                        <!-- PDF Link. -->
                        <span class="link-block">
                        <a href="https://arxiv.org/pdf/2303.13440.pdf"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                        </a>
                        </span>
                        <span class="link-block">
                        <a href="https://arxiv.org/abs/2303.13440"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                        </a>
                        </span>
                        <!-- Video Link. -->
                        <span class="link-block">
                        <a href=""
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="fab fa-youtube"></i>
                        </span>
                        <span>Video</span>
                        </a>
                        </span>
                        <!-- Code Link. -->
                        <span class="link-block">
                        <a href="https://aneeshan95.github.io/Sketch_LVM/"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                        <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                        </a>
                        </span>
                        <!-- Dataset Link. -->
                        <!-- <span class="link-block">
                           <a href=""
                              class="external-link button is-normal is-rounded is-dark">
                             <span class="icon">
                                 <i class="far fa-images"></i>
                             </span>
                             <span>Data</span>
                           </a> -->
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </div>
   </section>
   <section class="hero teaser">
      <div class="container is-max-desktop">
         <div class="hero-body">
            <img class="round" style="width:1500px" src="./static/images/teaser.png"/>
            <h2 class="subtitle has-text-centered">
               <span class="dnerf"></span> Against existing (left) ZS-SBIR methods, we adapt CLIP model for ZS-SBIR (middle), and extend to a more practical yet challenging setup of FG-ZS-SBIR (right), via a novel promptbased design. Our model surpasses prior arts by a high margin.</h2>
         </div>
      </div>
   </section>
   <!-- <table border="1" id="cssTable">
      <tr>
          <td>Text</td>
          <td>Text</td>
      </tr>
      </table> -->
   <!-- 
      <section class="hero is-light is-small">
        <div class="hero-body">
          <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
              <div class="item item-steve">
                <video poster="" id="steve" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-chair-tp">
                <video poster="" id="chair-tp" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-shiba">
                <video poster="" id="shiba" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-fullbody">
                <video poster="" id="fullbody" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-blueshirt">
                <video poster="" id="blueshirt" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-mask">
                <video poster="" id="mask" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-coffee">
                <video poster="" id="coffee" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-toby">
                <video poster="" id="toby" autoplay controls muted loop height="100%">
                  <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
      </section>
       -->
   <section class="section">
   <div class="container is-max-desktop">
   <!-- Abstract. -->
   <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
         <h2 class="title is-3">Abstract</h2>
         <div class="content has-text-justified">
            In this paper, we leverage CLIP for zero-shot sketch based image retrieval (ZS-SBIR). We are largely inspired by recent advances on foundation models and the unparalleled generalisation ability they seem to offer, but for the first time tailor it to benefit the sketch community. We put forward novel designs on how best to achieve this synergy, for both the category setting and the fine-grained setting ("all"). At the very core of our solution is a prompt learning setup. First we show just via factoring in sketch-specific prompts, we already have a category-level ZS-SBIR system that overshoots all prior arts, by a large margin (24.8%) - a great testimony on studying the CLIP and ZS-SBIR synergy. Moving onto the fine-grained setup is however trickier, and requires a deeper dive into this synergy. For that, we come up with two specific designs to tackle the fine-grained matching nature of the problem: (i) an additional regularisation loss to ensure the relative separation between sketches and photos is uniform across categories, which is not the case for the gold standard standalone triplet loss, and (ii) a clever patch shuffling technique to help establishing instance-level structural correspondences between sketch-photo pairs. With these designs, we again observe significant performance gains in the region of 26.9% over previous state-of-the-art. The take-home message, if any, is the proposed CLIP and prompt learning paradigm carries great promise in tackling other sketch-related tasks (not limited to ZS-SBIR) where data scarcity remains a great challenge. Code and models will be made available.
            </p>
         </div>
      </div>
   </div>
   <!--/ Abstract. -->
   <!-- Paper video. -->
   <!-- <section class="section">
      <div class="container is-max-desktop">
      -- Abstract. --
      <div class="columns is-centered has-text-centered">
         <div class="column is-four-fifths">
            <h2 class="title is-3">Method</h2>
            <div class="content has-text-justified">
               </h2>
               <center>
                  <img src="./static/images/solution.png" alt="" border=0 height=300 width=650></img></
               </center>
               <h5 class="subtitle has-text-centered">
               The sketch mapper aims to predict the corresponding latent code of associated photo in the manifold of pre-trained GAN.
			   </h5>
               &nbsp; 
            </div>
         </div>
      </div>
   </section> -->
   
   
   <section class="section">
      <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
         <div class="column is-four-fifths">
            <h2 class="title is-3">Architecture</h2>
            <div class="content has-text-justified">
               </h2>
               <center>
                  <img src="./static/images/arch.png" alt="" border=0 height=300 width=650></img></
               </center>
               <h5 class="subtitle has-text-centered">
                  Cross-category FG-ZS-SBIR. A common (photo-sketch) learnable visual prompt shared across categories is trained using CLIP’s image encoder over three losses as shown. CLIP’s textencoder based classification loss is used during training.
			      </h5
               &nbsp; 
            </div>
         </div>
      </div>
   </section>

   <section class="hero">
   <div class="hero-body">
   <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
         <div class="column is-four-fifths">
            <h2 class="title is-3">Results</h2>
            <div class="content has-text-justified">
               <center>
                  <img src="static/images/qual_cat.png" alt="this slowpoke moves" border=0 height=200 width=1500/>
               </center>
               <h5 class="subtitle has-text-centered">
                  Qualitative results of ZS-SBIR on Sketchy by a baseline (blue) method vs Ours (green).
			   <br>
			   <br>			
               <center>
                  <img src="static/images/qual_FG.png" alt="this slowpoke moves" border=0 height=200 width=600/>
               </center>
               <h5 class="subtitle has-text-centered">
                  Qualitative results of FG-ZS-SBIR on Sketchy by a baseline (blue) method vs Ours (green). The images are arranged in increasing order of the ranks beside their corresponding sketch-query, i.e the left-most image was retrieved at rank-1 for every category. The true-match for every query, if appearing in top-5 is marked in a green frame. Numbers denote the rank at which that true-match is retrieved for every corresponding sketch-query.
            <br>
			   <!-- <br>
               <center>
                  <img src="static/images/noisy.gif" alt="this slowpoke moves" border=0 height=400 width=800/>
               </center>
               <h5 class="subtitle has-text-centered">
               Effect of noisy stroke addition (left) and generation from partial sketches (right).		
			   <br>
			   <br>
			   <center>
                  <img src="static/images/unseen.gif" alt="this slowpoke moves" border=0 height=400 width=800/>
               </center>
               <h5 class="subtitle has-text-centered">
               Generalisation across sketch styles.	
			   <br>
			   <br>
			   <center>
                  <img src="static/images/multiModal.gif" alt="this slowpoke moves" border=0 height=400 width=800/>
               </center>
               <h5 class="subtitle has-text-centered">
               Multi-modal generation showing varied colour and, appearance features. Reference photo shown in inset.		
			   <br>
			   <br>
			   <center>
                  <img src="static/images/suppl.gif" alt="this slowpoke moves" border=0 height=400 width=800/>
               </center>
               <h5 class="subtitle has-text-centered">
			   Qualitative results on ShoeV2, ChairV2, and Handbag datasets.				    -->
            </div>
         </div>
      </div>
   </div>
   <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
         <h2 class="title">BibTeX</h2>
         <pre><code>@article{koley2023picture,
  title={{CLIP for All Things Zero-Shot Sketch-Based Image Retrieval, Fine-Grained or Not}},
  author={Aneeshan Sain and Ayan Kumar Bhunia and Pinaki Nath Chowdhury and Subhadeep Koley and Tao Xiang and Yi-Zhe Song},
  booktitle={CVPR},
  year={2023}
}</code></pre>
      </div>
   </section>
   <script>
      const viewers = document.querySelectorAll(".image-compare");
      viewers.forEach((element) => {
          let view = new ImageCompare(element, {
              hoverStart: true,
              addCircle: true
          }).mount();
      });
      
      $(document).ready(function () {
          var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
              lineNumbers: false,
              lineWrapping: true,
              readOnly: true
          });
          $(function () {
              $('[data-toggle="tooltip"]').tooltip()
          })
      });
   </script>
   <br>
   <p style="text-align:center">Copyright © Aneeshan Sain | Last updated: 24 Mar 2023 |Template Credit: <a href="https://nerfies.github.io/"> Nerfies</a></p>
   </body>
</html>